# RoSeLLa
# í•œêµ­ì–´ ê¸°ë°˜ ì†Œí˜• ì–¸ì–´ ëª¨ë¸(sLM)

RoSeLLaëŠ” NLPLABì—ì„œ êµ¬ì¶•í•œ [NLPLAB sLM ë°ì´í„°ì…‹](https://github.com/NLPlab-skku/DATA/tree/main/sLM)ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•œ í•œêµ­ì–´ ì†Œí˜• ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.<br/>
[ğŸ¤—42dot/42dot_LLM-PLM-1.3B](https://huggingface.co/42dot/42dot_LLM-PLM-1.3B)ì„ ê¸°ë°˜ìœ¼ë¡œ instruction tuning ëœ ëª¨ë¸ì…ë‹ˆë‹¤.


## RoSeLLa.v0
NLPLAB sLM ë°ì´í„°ì…‹ì„ instruction tuning í•œ ëª¨ë¸ì…ë‹ˆë‹¤.<br/>
- Repo: [ğŸ¤—NLPlab-skku/Rosella_v0](https://huggingface.co/NLPlab-skku/RoSeLLa_v0) <br/>

|ë°ì´í„°ì…‹|ê°œìˆ˜|
|------|---|
|**CoT**|77,200|
|**Dolly**|6,642|
|**EverythingLM**|991|
|**Law**|13,702|
|**Number**|9,580|

## RoSeLLa.v1
NLPLAB sLM ë°ì´í„°ì…‹ì„ 2ì°¨ ê°€ê³µí•˜ì—¬ instruction tuning í•œ ëª¨ë¸ì…ë‹ˆë‹¤.<br/>
- Repo: [ğŸ¤—NLPlab-skku/Rosella_v1](https://huggingface.co/NLPlab-skku/RoSeLLa_v1) <br/>

v0ì˜ ë°ì´í„° ì…‹ì˜ ì¼ë¶€ë¥¼ gpt-4oë¥¼ í†µí•˜ì—¬ í•„í„°ë§í•˜ì˜€ìŠµë‹ˆë‹¤. <br/>

## RoSeLLa.v2 (ì§„í–‰ì¤‘)
ê¸°ì¡´ ì˜¤í”ˆì†ŒìŠ¤ LLMì„ í™œìš©í•˜ì—¬ Pruning ë° Knowledge Distillation ê¸°ë²•ì„ ì ìš©í•œ ê²½ëŸ‰í™” ëª¨ë¸ì…ë‹ˆë‹¤.
- Repo: (7~8ì›” ì¤‘ ê³µê°œ ì˜ˆì •)

Base Model: Llama-3-3B, Qwen2.5-3B, Gemma-2B ë“±

**Pruning:** <br/>
1. ì¤‘ìš”ë„ê°€ ë‚®ì€ attention/MLP weight ì œê±° (Magnitude-based & Head-wise pruning) <br/>
2. ì¤‘ìš”ë„ê°€ ë‚®ì€ Layer ì œê±°

**Knowledge Distillation:** ê° Base Modelì„ êµì‚¬(teacher)ë¡œ ì„¤ì •í•˜ì—¬ Hidden States, Logits, Final Outputì„ ê¸°ë°˜ìœ¼ë¡œ Student ëª¨ë¸ì„ í•™ìŠµ

ê¸°ë°˜ ë°ì´í„° : [openwebtext](https://skylion007.github.io/OpenWebTextCorpus)

ì´í›„ ì „ì²´ ê³¼ì •ì„ **ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰**

ëª©í‘œ: ëª¨ë¸ í¬ê¸° ë° ì¶”ë¡  ë¹„ìš©ì„ ì¤„ì´ë©´ì„œë„ ê¸°ì¡´ Instruction ëŠ¥ë ¥ ìœ ì§€
